{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Zy_XFVgVckTk"
      },
      "source": [
        "## EE 461P: Data Science Principles  \n",
        "### Homework 5\n",
        "### Total points: 100 points \n",
        "### Due: 14th April, 11:59pm    \n",
        "\n",
        "Your homework should be written in a **Jupyter notebook**. You may work in groups of two if you wish. Only one student per team needs to submit the assignment on Canvas.  But be sure to include name and UT eID for both students.  Homework groups will be created and managed through Canvas, so please do not arbitrarily change your homework group. If you do change, let the TAs know.\n",
        "\n",
        "Also, please make sure your code runs and the graphics (and anything else) are displayed in your notebook before submitting. (%matplotlib inline)\n",
        "\n",
        "### Name(s) and EID(s):\n",
        "1. Mervan Can Kaya, mk45596\n",
        "2. Jacob Dahlkvist, jad7543\n",
        "\n",
        "### Homework group No.: 20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmLndaMeDwrb"
      },
      "source": [
        "# Question 1: Bayesian Belief Networks [15 pts]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LltKbWoIhdfz"
      },
      "source": [
        "Refer to the Bayesian Network Belief [image](https://drive.google.com/file/d/1dn5nwLxzzPk-HRqlF-JJZvREf1fPZG__/view?usp=share_link) for this question. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-uiFrHzrn27"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1dn5nwLxzzPk-HRqlF-JJZvREf1fPZG__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WX3FxClD-n7"
      },
      "source": [
        "All nodes are binary and can take 0/1 values\n",
        "\n",
        "The probabilities are given below:\n",
        "\n",
        "P(Season = 1) = .001   \n",
        "P(Atmospheric Pressure = 1) = .0.002\n",
        "\n",
        "\n",
        "P(Rain = 1 | Season = 0, Atmospheric Pressure = 0) = .001  \n",
        "P(Rain = 1 | Season = 0, Atmospheric Pressure = 1) = .29  \n",
        "P(Rain = 1 | Season = 1, Atmospheric Pressure = 0) = .94  \n",
        "P(Rain = 1 | Season = 1, Atmospheric Pressure = 1) = .95\n",
        "\n",
        "P(Umbrella = 1 | Rain = 1) = .9  \n",
        "P(Umbrella = 1 | Rain = 0) = .05\n",
        "\n",
        "For the given Bayesian network, compute the following probabilities : \n",
        "\n",
        "\n",
        "1.1 Find the probability that  Umbrella = 0. (4 points)\n",
        "\n",
        "1.2  Given that there is low Atmospheric Pressure (Atmospheric Pressure = 0), what is the probability that Rain = 1. (4 points)\n",
        "\n",
        "1.3  Given that it rains(Rain = 1), what is the probability that the it is rainy season (Season = 1). (7 points)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "klZrfH7AEJdi"
      },
      "source": [
        "Answer:\n",
        "1.1 \n",
        "\n",
        "Law of total probability:\n",
        "\n",
        "\\begin{align*}\n",
        "P(Umbrella = 0) &= P(Umbrella = 0 | Rain = 0) \\times P(Rain = 0) + P(Umbrella = 0 | Rain = 1) \\times P(Rain = 1) \\\\\n",
        "&= (1 - P(Umbrella = 1 | Rain = 0)) \\times (1 - P(Rain = 1)) + (1 - P(Umbrella = 1 | Rain = 1)) \\times P(Rain = 1) \\\\\n",
        "&= (1 - 0.05) \\times (1 - P(Rain = 1)) + (1 - 0.9) \\times P(Rain = 1) \\\\\n",
        "&= 0.95 \\times (1 - P(Rain = 1)) + 0.1 \\times P(Rain = 1)\n",
        "\\end{align*}\n",
        "\n",
        "\\begin{align*}\n",
        "P(Rain = 1) &= P(Rain = 1 | Season = 0, Atmospheric Pressure = 0) \\times P(Season = 0) \\times P(Atmospheric Pressure = 0) \\\\\n",
        "&+ P(Rain = 1 | Season = 0, Atmospheric Pressure = 1) \\times P(Season = 0) \\times P(Atmospheric Pressure = 1) \\\\\n",
        "&+ P(Rain = 1 | Season = 1, Atmospheric Pressure = 0) \\times P(Season = 1) \\times P(Atmospheric Pressure = 0) \\\\\n",
        "&+ P(Rain = 1 | Season = 1, Atmospheric Pressure = 1) \\times P(Season = 1) \\times P(Atmospheric Pressure = 1) \\\\\n",
        "&= 0.001 \\times 0.999 \\times 0.998 + 0.29 \\times 0.999 \\times 0.002 \\\\\n",
        "&+ 0.94 \\times 0.001 \\times 0.998 + 0.95 \\times 0.001 \\times 0.002 \\\\\n",
        "&= 0.00251863\n",
        "\\end{align*}\n",
        "\n",
        "\\begin{align*}\n",
        "P(Umbrella = 0) &= 0.95 \\times (1 - 0.00251863) + 0.1 \\times 0.00251863 \\\n",
        "&= 0.9476035\n",
        "\\end{align*}\n",
        "\n",
        "1.2 \n",
        "\n",
        "Bayes theorem:\n",
        "\n",
        "$P(Rain = 1 \\mid Atmospheric Pressure = 0) = \\frac{P(Atmospheric Pressure = 0 \\mid Rain = 1) \\cdot P(Rain = 1)}{P(Atmospheric Pressure = 0)}$\n",
        "\n",
        "\\begin{aligned}\n",
        "P(Atmospheric Pressure = 0) &= P(Atmospheric Pressure = 0 \\mid Season = 0) \\cdot P(Season = 0) + P(Atmospheric Pressure = 0 \\mid Season = 1) \\cdot P(Season = 1) \\\\\n",
        "&= (1 - P(Rain = 1 \\mid Season = 0, Atmospheric Pressure = 0)) \\cdot P(Season = 0) \\\\\n",
        "&\\quad + (1 - P(Rain = 1 \\mid Season = 1, Atmospheric Pressure = 0)) \\cdot P(Season = 1) \\\\\n",
        "&= (1 - 0.001) \\cdot 0.999 + (1 - 0.94) \\cdot 0.001 \\\\\n",
        "&= 0.000999 + 0.00006 \\\\\n",
        "&= 0.001059\n",
        "\\end{aligned}\n",
        "\n",
        "\\begin{aligned}\n",
        "P(Rain = 1 \\mid Atmospheric Pressure = 0) &= \\frac{P(Atmospheric Pressure = 0 \\mid Rain = 1) \\cdot P(Rain = 1)}{P(Atmospheric Pressure = 0)} \\\\\n",
        "&= \\frac{(1 - P(Atmospheric Pressure = 1 \\mid Rain = 1)) \\cdot P(Rain = 1)}{P(Atmospheric Pressure = 0)} \\\\\n",
        "&\\approx 0.047\n",
        "\\end{aligned}\n",
        "\n",
        "1.3\n",
        "\n",
        "Bayes theorem:\n",
        "\n",
        "$P(Season = 1 | Rain = 1) = \\frac{P(Rain = 1 | Season = 1) \\times P(Season = 1)}{P(Rain = 1)}$\n",
        "\n",
        "Law of total probability:\n",
        "\n",
        "$P(Rain = 1) = P(Rain = 1 | Season = 0, Atmospheric Pressure = 0) \\times P(Season = 0) \\times P(Atmospheric Pressure = 0) + P(Rain = 1 | Season = 0, Atmospheric Pressure = 1) \\times P(Season = 0) \\times P(Atmospheric Pressure = 1) + P(Rain = 1 | Season = 1, Atmospheric Pressure = 0) \\times P(Season = 1) \\times P(Atmospheric Pressure = 0) + P(Rain = 1 | Season = 1, Atmospheric Pressure = 1) \\times P(Season = 1) \\times P(Atmospheric Pressure = 1)$\n",
        "\n",
        "$P(Rain = 1) = 0.001 \\times 0.999 \\times 0.998 + 0.29 \\times 0.999 \\times 0.002 + 0.94 \\times 0.001 \\times 0.998 + 0.95 \\times 0.001 \\times 0.002$\n",
        "$= 0.00094398 + 0.00057502 + 0.0009386 + 0.00000095$\n",
        "$= 0.00245855$\n",
        "\n",
        "$P(Season = 1 | Rain = 1) = \\frac{0.95 \\times 0.001}{0.00245855} = 0.386$ = 38.6%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtGre3IncorE"
      },
      "source": [
        "## Q2. Logistic Regression (20 points)\n",
        "\n",
        "2.1 Suppose you are trying to learn a logistic regression based classifier on a dataset $D = (x_i, y_i)^n$, i.e., you have n data samples in this dataset where each $x_i$ is a d-dimensional vector and $y_i \\in \\{-1,1\\}$. Learning this classifier requires to find optimal $w$ and $b$ so that the probability of a data point $x$ belonging to class 1 is given by $\\sigma(w^Tx+b)$ where $\\sigma$ is the sigmoid function. Write the cost function as a function of $w$ and $b$ for this problem in a way that it tries to minimize the log loss function over the given dataset. You can learn more about the log loss [here](https://developers.google.com/machine-learning/crash-course/logistic-regression/model-training). (10 points)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIPaEHeyenD-"
      },
      "source": [
        "2.2 Now consider a simpler problem with 2-dimensional data $x = [x_1, x_2]$. Given you have learnt optimal $w = [1,2]$ and $b = 0$. Draw the decision boundary for this classifier. Given this decision boundary, how do you classify a point $x=[1,1]$? (8+2=10 points)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2QjVoh8WhRhg"
      },
      "source": [
        "Answer:\n",
        "\n",
        "2.1 \n",
        "\n",
        "Log loss = $\\displaystyle\\sum_{i=1}^{n} (-y_i \\log(y') - (1-y_i) \\log(1-y'))$\n",
        "\n",
        "where $y' = \\sigma(w^Tx+b)$.\n",
        "\n",
        "Log loss = $\\displaystyle\\sum_{i=1}^{n} (-(1+y_i) \\log(\\sigma(w^Tx_i+b)) - (1-y_i) \\log(1-\\sigma(w^Tx_i+b)))$\n",
        "\n",
        "2.2 \n",
        "\n",
        "By inserting $w = [1,2]$ and $b = 0$ in the equation $w^Tx + b = 0$ we get $x_1 + 2x_2 = 0$. This equation gives us the decision boundary which looks like this:\n",
        "\n",
        "![alt text](DBoundary.png)\n",
        "\n",
        "\n",
        "To classify the point $x=[1,1]$, we can plug in the values of $x_1$ and $x_2$ into the equation of the decision boundary to get $1+2(1) = 3 > 0$, which means the point is on the positive side of the boundary. Therefore, it would be classified as belonging to class 1.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5-HxsO4hTzL"
      },
      "source": [
        "# Q3. Logistic Regression for Imbalanced Datasets (25 points)\n",
        "\n",
        "Consider a binary imbalanced class problem given in the [`hw5_classification_dataset.csv`](https://drive.google.com/file/d/1KAEOYPfMVw2oIhMIPGTXAriBNhPawZtI/view?usp=share_link). Load the dataset into a pandas dataframe and print label distribution.\n",
        "\n",
        "3.1 Data Pre-processing : Perform one-hot encoding of the features named `['InternetService','Contract','PaymentMethod']` to get the dummy features. (3 points)\n",
        "\n",
        "3.2 Training : Train a logistic regression classifier after splitting the data in train/test datasets using 80/20 split and random_state = 15. Obtain and report the confusion matrix, accuracy and the AUC-ROC score of the classifier on the test data. What do you observe with respect to the performance of the model on different classes? (10 points)\n",
        "\n",
        "3.3 Now, use class weights to modify the cost of wrong predictions for different classes differently by appropriately setting the `class_weight` parameter in the logistic regression classifier. Again print the confusion matrix, accuracy and the AUC-ROC score of the classifier on the test data. (7 points)\n",
        "\n",
        "3.4 Mention an alternative method that could be used to address class imbalance in classification problems, briefly explaining how this method works and providing a reference (5 points)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "kHcUr_z0IZDB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "df = pd.read_csv('hw5_classification_dataset.csv', index_col = [0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: title={'center': 'Count (Label)'}>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df['Label'].value_counts().plot(kind='bar', title='Count (Label)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "# One hot encoding the columns with categorical data\n",
        "df_ohe = df[['InternetService','Contract','PaymentMethod']]\n",
        "df_ohe = pd.get_dummies(df_ohe, drop_first = True)\n",
        "df = pd.concat([df, df_ohe], axis = 1)\n",
        "df.drop(['InternetService','Contract','PaymentMethod'], axis = 1, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "UwDi3DrMI1QN"
      },
      "outputs": [],
      "source": [
        "# Train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X = df.drop(['Label'], axis = 1)\n",
        "y = df['Label']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "qK8r4YxBJO-7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression\n",
            "Confusion Matrix\n",
            "[[950  90]\n",
            " [170 197]]\n",
            "F1 Score\n",
            "0.6024464831804281\n",
            "ROC AUC Score\n",
            "0.7251231398029763\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import f1_score, roc_auc_score\n",
        "# Answer here\n",
        "\n",
        "# Logistic Regression\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)\n",
        "y_pred = logreg.predict(X_test)\n",
        "print('Logistic Regression')\n",
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print('F1 Score')\n",
        "print(f1_score(y_test, y_pred))\n",
        "print('ROC AUC Score')\n",
        "print(roc_auc_score(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression\n",
            "Confusion Matrix\n",
            "[[746 294]\n",
            " [ 80 287]]\n",
            "F1 Score\n",
            "0.6054852320675105\n",
            "ROC AUC Score\n",
            "0.7496620205407671\n"
          ]
        }
      ],
      "source": [
        "# Modify class weights to get better results\n",
        "logreg = LogisticRegression(class_weight = 'balanced', max_iter = 10000)\n",
        "logreg.fit(X_train, y_train)\n",
        "y_pred = logreg.predict(X_test)\n",
        "print('Logistic Regression')\n",
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print('F1 Score')\n",
        "print(f1_score(y_test, y_pred))\n",
        "print('ROC AUC Score')\n",
        "print(roc_auc_score(y_test, y_pred))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Alt method of rebalancing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGEJne27SGfq"
      },
      "source": [
        "# Question 4 - Ensembles methods for classification (40 pts)\n",
        "\n",
        "We will use the dataset from the kaggle competition [GiveMeSomeCredit](https://www.kaggle.com/c/GiveMeSomeCredit). We will work on a smaller version of this dataset. The dataset is available on canvas as ensemble-dataset.csv. \n",
        "We will predict the probability that somebody will experience financial distress in the next two years. The dataset has already been split into train and test sets for you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "cKXWaSd6OH4A",
        "outputId": "eb8b7b6a-46c2-48e8-ac11-7a20d67ca3cc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SeriousDlqin2yrs</th>\n",
              "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
              "      <th>age</th>\n",
              "      <th>NumberOfTime30.59DaysPastDueNotWorse</th>\n",
              "      <th>DebtRatio</th>\n",
              "      <th>MonthlyIncome</th>\n",
              "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
              "      <th>NumberOfTimes90DaysLate</th>\n",
              "      <th>NumberRealEstateLoansOrLines</th>\n",
              "      <th>NumberOfTime60.89DaysPastDueNotWorse</th>\n",
              "      <th>NumberOfDependents</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1.062646</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "      <td>0.179032</td>\n",
              "      <td>3490</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0.003591</td>\n",
              "      <td>83</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000869</td>\n",
              "      <td>10352</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>100</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>52</td>\n",
              "      <td>0</td>\n",
              "      <td>0.336355</td>\n",
              "      <td>7060</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0.220152</td>\n",
              "      <td>54</td>\n",
              "      <td>0</td>\n",
              "      <td>0.235064</td>\n",
              "      <td>4083</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SeriousDlqin2yrs  RevolvingUtilizationOfUnsecuredLines  age  \\\n",
              "0                 0                              1.062646   50   \n",
              "1                 0                              0.003591   83   \n",
              "2                 0                              1.000000   22   \n",
              "3                 0                              0.000000   52   \n",
              "4                 0                              0.220152   54   \n",
              "\n",
              "   NumberOfTime30.59DaysPastDueNotWorse  DebtRatio  MonthlyIncome  \\\n",
              "0                                     2   0.179032           3490   \n",
              "1                                     0   0.000869          10352   \n",
              "2                                     0   0.000000            100   \n",
              "3                                     0   0.336355           7060   \n",
              "4                                     0   0.235064           4083   \n",
              "\n",
              "   NumberOfOpenCreditLinesAndLoans  NumberOfTimes90DaysLate  \\\n",
              "0                                8                        1   \n",
              "1                               14                        0   \n",
              "2                                1                        0   \n",
              "3                               10                        0   \n",
              "4                               15                        0   \n",
              "\n",
              "   NumberRealEstateLoansOrLines  NumberOfTime60.89DaysPastDueNotWorse  \\\n",
              "0                             0                                     1   \n",
              "1                             0                                     0   \n",
              "2                             0                                     0   \n",
              "3                             2                                     0   \n",
              "4                             0                                     0   \n",
              "\n",
              "   NumberOfDependents  \n",
              "0                   1  \n",
              "1                   0  \n",
              "2                   0  \n",
              "3                   3  \n",
              "4                   1  "
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('ensemble-dataset.csv')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gDtJv05SQ1a",
        "outputId": "8be1feeb-4eb1-4cf1-dbfc-d1ca4a0c79e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train (3382, 10) (3382,)\n",
            "test (1667, 10) (1667,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "y = data['SeriousDlqin2yrs']\n",
        "X = data.drop(['SeriousDlqin2yrs'],axis=1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42)\n",
        "\n",
        "print('train',X_train.shape,y_train.shape)\n",
        "print('test',X_test.shape,y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8go9I7xSVVJ"
      },
      "source": [
        "In this question, we will compare performance of different ensemble methods for classification problems: [Bagging](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html), [Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html), and [XGBoost](https://xgboost.readthedocs.io/en/stable/get_started.html) Classifiers. When training each of these models, use [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) to perform a hyperparameter search using only the train data with `cv=3`, and report the best hyperparameters you have found. For each of the models below, report the [log_loss](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.log_loss.html), accuracy_score, roc_auc_score and the [calibration curve plot](https://scikit-learn.org/stable/modules/generated/sklearn.calibration.CalibrationDisplay.html#sklearn.calibration.CalibrationDisplay.from_estimator) using the best hyperparameters you have found. \n",
        "\n",
        "4.1 Use an MLP with random_state = 42. (7 points)\n",
        "\n",
        "4.2 Use a Decision Tree Classifier with random_state = 42. (7 points)\n",
        "\n",
        "4.3 Create an ensemble of 20 classifiers (i.e n_estimators = 20) with random_state = 42 for [bagging](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html) with base classifier as Decision Tree Classifier from part 1. (7 points)\n",
        "\n",
        "4.4 Use a [Random Forest](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) classifier with random_state=42. (7 points)\n",
        "\n",
        "4.5 Use [XGBoost](https://xgboost.readthedocs.io/en/stable/get_started.html) with random_state=42. (7 points)\n",
        "\n",
        "4.6 Compare the performance of the decision tree and MLP with the ensemble methods based on the results you have obtained (all 4 metrics). (5 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "26y3CVzA40Bq"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import (train_test_split,GridSearchCV)\n",
        "from sklearn.metrics import (accuracy_score,roc_auc_score)\n",
        "from sklearn.ensemble import (RandomForestClassifier,GradientBoostingClassifier,AdaBoostClassifier)\n",
        "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from time import time\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "2cix_0SJ44YW"
      },
      "outputs": [],
      "source": [
        "columns_list = list(X.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "fgsy9L-N45-A"
      },
      "outputs": [],
      "source": [
        "def grid_search(model, params, model_name):\n",
        "    # define your GridSearchCV object with the relevant parameters\n",
        "    # TODO\n",
        "    cv = GridSearchCV(model, params, cv=3)\n",
        "\n",
        "    # fit the grid search model with the train data and print the best parameters\n",
        "    # TODO\n",
        "    cv.fit(X_train, y_train)\n",
        "    print()\n",
        "    print()\n",
        "    print(\"Best parameters for {} are {}\".format(model_name, cv.best_params_))\n",
        "\n",
        "    # use the fitted model with the best parameters to predict on the test set and report the metrics\n",
        "    # TODO\n",
        "    y_pred = cv.predict(X_test)\n",
        "    print(\"Accuracy score for {} is {}\".format(model_name, accuracy_score(y_test, y_pred)))\n",
        "    print(\"ROC AUC score for {} is {}\".format(model_name, roc_auc_score(y_test, y_pred)))\n",
        "    print(\"Confusion matrix for {} is {}\".format(model_name, confusion_matrix(y_test, y_pred)))\n",
        "    print(\"Classification report for {} is {}\".format(model_name, classification_report(y_test, y_pred)))\n",
        "    print()\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Best parameters for MLPClassifier are {'activation': 'relu', 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'shuffle': False, 'solver': 'adam', 'warm_start': True}\n",
            "Accuracy score for MLPClassifier is 0.9364127174565087\n",
            "ROC AUC score for MLPClassifier is 0.5092592592592593\n",
            "Confusion matrix for MLPClassifier is [[1559    0]\n",
            " [ 106    2]]\n",
            "Classification report for MLPClassifier is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97      1559\n",
            "           1       1.00      0.02      0.04       108\n",
            "\n",
            "    accuracy                           0.94      1667\n",
            "   macro avg       0.97      0.51      0.50      1667\n",
            "weighted avg       0.94      0.94      0.91      1667\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# MLPClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "mlp = MLPClassifier(random_state = 42, max_iter=1000)\n",
        "\n",
        "# Decision Tree Classifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dtc = DecisionTreeClassifier(random_state = 42)\n",
        "\n",
        "# Random Forest Classifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rfc = RandomForestClassifier(random_state = 42)\n",
        "\n",
        "# XGBoost Classifier\n",
        "from xgboost import XGBClassifier\n",
        "xgb = XGBClassifier(random_state = 42)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Grid search each model\n",
        "grid_search(mlp, {\n",
        "                  'hidden_layer_sizes': [(10,),(20,),(50,),(60,),(90,),(100,)],\n",
        "                  'activation': ['relu', 'logistic', 'tanh'],\n",
        "                  'solver': ['sgd', 'adam'],\n",
        "                  'learning_rate': ['adaptive', 'constant'],\n",
        "                  'shuffle': [True, False],\n",
        "                  'warm_start': [True, False]}, 'MLPClassifier')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Best parameters for DecisionTreeClassifier are {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': 20, 'min_samples_leaf': 1, 'min_samples_split': 1}\n",
            "Accuracy score for DecisionTreeClassifier is 0.9352129574085183\n",
            "ROC AUC score for DecisionTreeClassifier is 0.5732514907466799\n",
            "Confusion matrix for DecisionTreeClassifier is [[1542   17]\n",
            " [  91   17]]\n",
            "Classification report for DecisionTreeClassifier is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.97      1559\n",
            "           1       0.50      0.16      0.24       108\n",
            "\n",
            "    accuracy                           0.94      1667\n",
            "   macro avg       0.72      0.57      0.60      1667\n",
            "weighted avg       0.92      0.94      0.92      1667\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "grid_search(dtc, {\n",
        "                  'criterion': ['gini', 'entropy', 'log_loss'],\n",
        "                  'max_depth': [1,2,3,4,5,10,20],\n",
        "                  'min_samples_split': [1,2,3,4,5,10,20],\n",
        "                  'min_samples_leaf': [1,2,3,4,5,10,20],\n",
        "                  'max_features': ['sqrt', 'log2', 'auto'],\n",
        "                  'max_leaf_nodes': [1,2,3,4,5,10,20]},'DecisionTreeClassifier',)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Best parameters for RandomForestClassifier are {'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': 20, 'min_samples_leaf': 3, 'min_samples_split': 1, 'n_estimators': 40}\n",
            "Accuracy score for RandomForestClassifier is 0.9364127174565087\n",
            "ROC AUC score for RandomForestClassifier is 0.5437305490224028\n",
            "Confusion matrix for RandomForestClassifier is [[1551    8]\n",
            " [  98   10]]\n",
            "Classification report for RandomForestClassifier is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.97      1559\n",
            "           1       0.56      0.09      0.16       108\n",
            "\n",
            "    accuracy                           0.94      1667\n",
            "   macro avg       0.75      0.54      0.56      1667\n",
            "weighted avg       0.92      0.94      0.91      1667\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "grid_search(rfc, {\n",
        "                  'n_estimators': [10,20,30,40,50],\n",
        "                  'max_depth': [1,2,3,4,5,10,20],\n",
        "                  'min_samples_split': [1,2,3,4,5,10,20],\n",
        "                  'min_samples_leaf': [1,2,3,4,5,10,20],\n",
        "                  'max_features': ['sqrt', 'log2'],\n",
        "                  'max_leaf_nodes': [1,2,3,4,5,10,20]}, 'RandomForestClassifier')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Best parameters for XGBClassifier are {'grow_policy': 'depthwise', 'max_depth': 1, 'max_leaves': 1, 'n_estimators': 20}\n",
            "Accuracy score for XGBClassifier is 0.9370125974805039\n",
            "ROC AUC score for XGBClassifier is 0.5440512674316395\n",
            "Confusion matrix for XGBClassifier is [[1552    7]\n",
            " [  98   10]]\n",
            "Classification report for XGBClassifier is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97      1559\n",
            "           1       0.59      0.09      0.16       108\n",
            "\n",
            "    accuracy                           0.94      1667\n",
            "   macro avg       0.76      0.54      0.56      1667\n",
            "weighted avg       0.92      0.94      0.91      1667\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "grid_search(xgb, {\n",
        "                  'n_estimators': [10,20,30,40,50], \n",
        "                  'max_depth': [1,2,3,4,5,10,20],\n",
        "                  'max_leaves': [1,2,3,4,5,10,20],\n",
        "                  'grow_policy': ['depthwise','lossguide']}, 'XGBClassifier')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Best parameters for BaggingClassifier are {'bootstrap': True, 'max_features': 1, 'max_samples': 1, 'n_estimators': 20}\n",
            "Accuracy score for BaggingClassifier is 0.9352129574085183\n",
            "ROC AUC score for BaggingClassifier is 0.5\n",
            "Confusion matrix for BaggingClassifier is [[1559    0]\n",
            " [ 108    0]]\n",
            "Classification report for BaggingClassifier is               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97      1559\n",
            "           1       0.00      0.00      0.00       108\n",
            "\n",
            "    accuracy                           0.94      1667\n",
            "   macro avg       0.47      0.50      0.48      1667\n",
            "weighted avg       0.87      0.94      0.90      1667\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Bagging Classifier using Decision Tree Classifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "bagging = BaggingClassifier(estimator = dtc, random_state = 42)\n",
        "grid_search(bagging, {'n_estimators': [20], \n",
        "                      \"max_samples\": [1,2,3,4,5,10,20], \n",
        "                      \"max_features\": [1,2,3,4,5,10,20], \n",
        "                      \"bootstrap\": [True, False]}, 'BaggingClassifier')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NblG4pg140ga"
      },
      "source": [
        "Answer:"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
